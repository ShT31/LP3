import pandas as pd
import numpy as np
df = pd.read_csv('Churn_Modelling.csv')
df

df = df.drop(['CustomerId','Surname'],axis=1)
df.info()

from sklearn.preprocessing import LabelEncoder
label_encoder = LabelEncoder()
df['Gender'] = label_encoder.fit_transform(df['Gender'])
df = pd.get_dummies(df, columns=['Geography'], drop_first=True)

x = df.drop('Exited', axis=1)  # All columns except 'Exited' are features
y = df['Exited']  # 'Exited' column is the target variable

from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
x_train = scaler.fit_transform(x_train)
x_test = scaler.transform(x_test) 

pip install tensorflow

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Input, Dense, Dropout

model = Sequential([
    Input(shape=(x_train.shape[1],)),  # Input layer: number of features as input size
    Dense(64, activation='relu'),  # Hidden layer with 64 units and ReLU activation function
    Dropout(0.5),  # Dropout layer to prevent overfitting, randomly dropping 50% of nodes
    Dense(32, activation='relu'),  # Hidden layer with 32 units and ReLU activation function
    Dropout(0.5),  # Dropout layer
    Dense(1, activation='sigmoid')  # Output layer with 1 unit and sigmoid activation for binary classification
])

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
history = model.fit(x_train, y_train, epochs=50, batch_size=32, validation_split=0.2)

import seaborn as sns
from sklearn.metrics import accuracy_score, confusion_matrix

y_pred = (model.predict(x_test) > 0.5).astype("int32")

accuracy = accuracy_score(y_test, y_pred)
conf_matrix = confusion_matrix(y_test, y_pred)

print(f"Accuracy: {accuracy}")
print("Confusion Matrix:")
print(conf_matrix)
sns.heatmap(data=conf_matrix, annot=True)

import matplotlib.pyplot as plt
plt.plot(np.array(history.history['accuracy']) * 100)
plt.plot(np.array(history.history['val_accuracy']) * 100)
plt.ylabel('accuracy')
plt.xlabel('epochs')
plt.legend(['train', 'validation'])
plt.title('Accuracy over epochs')
plt.show()